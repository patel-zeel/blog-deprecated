{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022-06-10-JaxOptimizers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4v19WFfzv9Y1OH8FjCz8d"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# JAX Optimizers\n",
        "\n",
        "> Pros and cons of several jax optimizers.\n",
        "\n",
        "- toc: true\n",
        "- badges: true\n",
        "- comments: true\n",
        "- author: Zeel B Patel\n",
        "- categories: [ML]"
      ],
      "metadata": {
        "id": "IvUYZ2CHCsYt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sOLzqiZZyVqF"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -U jax\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "try:\n",
        "  import jaxopt\n",
        "except ModuleNotFoundError:\n",
        "  %pip install -qq jaxopt\n",
        "  import jaxopt\n",
        "try:\n",
        "  import optax\n",
        "except ModuleNotFoundError:\n",
        "  %pip install -qq optax\n",
        "  import optax\n",
        "\n",
        "import tensorflow_probability.substrates.jax as tfp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function"
      ],
      "metadata": {
        "id": "uu6QaUkZ1BaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fun(x, a):\n",
        "  return (((x['param1'] - a) + (x['param2'] - (a+1)))**2).sum()"
      ],
      "metadata": {
        "id": "OL0jrlLMyhHx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial parameters"
      ],
      "metadata": {
        "id": "qovNfTZU1DUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 3\n",
        "init_params = lambda: {'param1': jnp.zeros(N), 'param2': jnp.ones(N)}\n",
        "a = 2.0"
      ],
      "metadata": {
        "id": "R40W08-jyy24"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizers"
      ],
      "metadata": {
        "id": "Mp1TNzE61Fa5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JaxOpt ScipyMinimize"
      ],
      "metadata": {
        "id": "sqfcbRFdzG2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "solver = jaxopt.ScipyMinimize('L-BFGS-B', fun=loss_fun)\n",
        "ans = solver.run(init_params(), a)\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0E10mnHzFlE",
        "outputId": "00736b13-a770-452d-db7d-c708c8045da5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OptStep(params={'param1': DeviceArray([1.9999999, 1.9999999, 1.9999999], dtype=float32), 'param2': DeviceArray([3., 3., 3.], dtype=float32)}, state=ScipyMinimizeInfo(fun_val=DeviceArray(4.2632564e-14, dtype=float32), success=True, status=0, iter_num=2))\n",
            "CPU times: user 78.3 ms, sys: 18.5 ms, total: 96.8 ms\n",
            "Wall time: 95.8 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pros\n",
        "* Two lines of code will do it all.\n",
        "\n",
        "#### Cons\n",
        "* It only returns the final parameters and final loss. No option to retrive in-between loss values."
      ],
      "metadata": {
        "id": "qhSn6XW50LWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optax"
      ],
      "metadata": {
        "id": "Y4b0gjLF0TMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "optimizer = optax.adam(learning_rate=0.1)\n",
        "value_and_grad_fun = jax.jit(jax.value_and_grad(loss_fun, argnums=0))\n",
        "params = init_params()\n",
        "state = optimizer.init(params)\n",
        "\n",
        "for _ in range(100):\n",
        "  loss_value, gradients = value_and_grad_fun(params, a)\n",
        "  updates, state = optimizer.update(gradients, state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "\n",
        "print(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZxHoAoWzpAl",
        "outputId": "0427970b-4d02-4c3a-9976-0dbcfd069508"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'param1': DeviceArray([2.0084236, 2.0084236, 2.0084236], dtype=float32), 'param2': DeviceArray([3.0084238, 3.0084238, 3.0084238], dtype=float32)}\n",
            "CPU times: user 3.09 s, sys: 63.4 ms, total: 3.16 s\n",
            "Wall time: 4.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pros:\n",
        "* Full control in user's hand. We can save intermediate loss values.\n",
        "\n",
        "#### Cons:\n",
        "* Its code is verbose, similar to PyTorch optimizers. "
      ],
      "metadata": {
        "id": "wwjqkeQd2SLO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Jaxopt OptaxSolver"
      ],
      "metadata": {
        "id": "a9l-2V3F3gPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "optimizer = optax.adam(learning_rate=0.1)\n",
        "solver = jaxopt.OptaxSolver(loss_fun, optimizer, maxiter=100)\n",
        "ans = solver.run(init_params(), a)\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB_KWP5b1nUb",
        "outputId": "e393257f-00c5-421c-bd65-fba0799c78c2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OptStep(params={'param1': DeviceArray([2.008423, 2.008423, 2.008423], dtype=float32), 'param2': DeviceArray([3.008423, 3.008423, 3.008423], dtype=float32)}, state=OptaxState(iter_num=DeviceArray(100, dtype=int32, weak_type=True), value=DeviceArray(0.00113989, dtype=float32), error=DeviceArray(0.09549397, dtype=float32), internal_state=(ScaleByAdamState(count=DeviceArray(100, dtype=int32), mu={'param1': DeviceArray([0.02871927, 0.02871927, 0.02871927], dtype=float32), 'param2': DeviceArray([0.02871927, 0.02871927, 0.02871927], dtype=float32)}, nu={'param1': DeviceArray([0.44847375, 0.44847375, 0.44847375], dtype=float32), 'param2': DeviceArray([0.44847375, 0.44847375, 0.44847375], dtype=float32)}), EmptyState()), aux=None))\n",
            "CPU times: user 719 ms, sys: 13.4 ms, total: 732 ms\n",
            "Wall time: 1.09 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pros:\n",
        "* Less lines of code.\n",
        "* Applies `lax.scan` internally to make it fast [[reference](https://github.com/google/jaxopt/blob/60f3425f70bc6a9555cc13dcc993933dc2772c7d/jaxopt/_src/loop.py#L68)].\n",
        "\n",
        "#### Cons:\n",
        "* Not able to get in-between state/loss values"
      ],
      "metadata": {
        "id": "j6iCcmvY6V8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tfp math minimize"
      ],
      "metadata": {
        "id": "2d1i5CtD7o_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "optimizer = optax.adam(learning_rate=0.1)\n",
        "params, losses = tfp.math.minimize_stateless(loss_fun, (init_params(), a), num_steps=1000, optimizer=optimizer)\n",
        "print(params)\n",
        "print(losses[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2-eDVMg6la1",
        "outputId": "f10e36bd-93f7-4e10-829c-0afb94e2b815"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'param1': DeviceArray([1.0000008, 1.0000008, 1.0000008], dtype=float32), 'param2': DeviceArray([1.9999989, 1.9999989, 1.9999989], dtype=float32)}, DeviceArray(0.9999999, dtype=float32))\n",
            "[48.       38.88006  30.751791 23.626852 17.507807]\n",
            "CPU times: user 880 ms, sys: 15.2 ms, total: 895 ms\n",
            "Wall time: 1.53 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pros:\n",
        "* One line of code to optimize the function and return in-between losses.\n",
        "\n",
        "#### Cons:\n",
        "* By default, it optimizes all arguments passed to the loss function. In above example, we can not control if `a` should be optimized or not. I have raised an issue [here](https://github.com/tensorflow/probability/issues/1575) for this problem."
      ],
      "metadata": {
        "id": "pIHAVvUuB9HP"
      }
    }
  ]
}