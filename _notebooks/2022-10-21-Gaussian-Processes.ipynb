{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6020e7",
   "metadata": {},
   "source": [
    "# Gaussian Processes - A no-skip-math version\n",
    "> End-to-end math derivations for Gaussian process regression and classification\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Zeel B Patel\n",
    "- categories: [ML]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c052daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from tinygp.kernels import ExpSquared\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dfc485",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "In this post, we will consider the regression problem of finding a reasonable map $X \\to \\boldsymbol{y}$ along with uncertainty. We can do this in a simplest setting with Bayesian linear regression assuming a **M**ulti**V**ariate **N**ormal (MVN) prior $\\boldsymbol{\\theta} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_\\theta, \\Sigma_\\theta)$ (why MVN? because $\\theta \\in (-\\infty, \\infty)$) and Normal likelihood $y \\sim \\mathcal{N}(\\boldsymbol{x}^T\\theta, \\sigma_n^2)$ with i.i.d. assumption.\n",
    "\n",
    "To start with Gaussian process regression, let us first focus on $\\boldsymbol{y}$ (and ignore $X$). We assume $\\boldsymbol{f}$ as a random variable and $\\boldsymbol{y}$ as a realization of $\\boldsymbol{f}$ with some noise. It would be a natural probabilistic assumption to assume $\\boldsymbol{f}$ to be MVN distributed since its range is $(-\\infty, \\infty)$. \n",
    "\n",
    "\\begin{equation}\n",
    "p(\\boldsymbol{f}) \\sim \\mathcal{N}(\\boldsymbol{m}_f, K_{ff})\n",
    "\\tag{prior}\n",
    "\\end{equation}\n",
    "\n",
    "Now, we need to bring in $X$ in a reasonable way to this formulation. A core assumption connecting $X$ with $\\boldsymbol{y}$ is the following:\n",
    "> if two inputs $\\boldsymbol{x}$ and $\\boldsymbol{x}'$ are close to each other (how to define the closeness? kernels!), corresponding $\\boldsymbol{y}$ and $\\boldsymbol{y}'$ are likely to be similar.\n",
    "\n",
    "We use something known as covariance function or kernel (later is more prevalent) to define this closeness. For example, RBF or squared exponential is a well-known kernel:\n",
    "\n",
    "\\begin{equation}\n",
    "k_{RBF}(\\boldsymbol{x}, \\boldsymbol{x}') = \\sigma^2 \\exp \\left(-{\\frac {\\|\\boldsymbol{x} -\\boldsymbol{x}' \\|^{2}}{2\\ell ^{2}}}\\right)\n",
    "\\tag{kernel}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5b7ac0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = jnp.array(0.0).reshape(1, 1)\n",
    "x_prime = jnp.linspace(-5,5,100).reshape(-1, 1)\n",
    "\n",
    "plt.plot(x_prime, ExpSquared()(x_prime, x));\n",
    "plt.xlabel(\"$x'$\")\n",
    "plt.title(f\"$k(x,x')$ where $x={x[0][0]}$ and $x' \\in ${plt.xlim()}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82608c9e",
   "metadata": {},
   "source": [
    "The plot above shows that value of $k(\\boldsymbol{x}, \\boldsymbol{x}')$ increases as $\\boldsymbol{x}'$ approaches $\\boldsymbol{x}$ and reduces as it moves far from $\\boldsymbol{x}$. Now, we will connect $X$ with $\\boldsymbol{f}$ (and thus with $\\boldsymbol{y}$) through kernel $k$ with two following assumptions:\n",
    "\n",
    "1. Diagonal entries of $K_{ff}$ represent variance of $f_i$, which can be represented by $k(\\boldsymbol{x}_i, \\boldsymbol{x}_i)$.\n",
    "2. Non-diagonal entries of $K_{ff}$ represent covariance between $f_i$ and $f_j$ and can be represented by $k(\\boldsymbol{x}_i, \\boldsymbol{x}_j)$.\n",
    "\n",
    "At this point, we have made everything clear about prior $p(\\boldsymbol{f}) \\sim \\mathcal{N}(\\boldsymbol{m}_f, K_{ff})$. Now, we will look at the likelihood. As mentioned earlier, $\\boldsymbol{y}$ is noisy realization of $f$ so the following likelihood would be a simple and natural choice.\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\boldsymbol{y}|\\boldsymbol{f}) \\sim \\mathcal{N}(\\boldsymbol{f}, \\sigma_n^2I)\n",
    "\\tag{likelihood}\n",
    "\\end{equation}\n",
    "\n",
    "Till now, we followed bottom-up approach and defined prior and likelihood for this problem. Now we will explore the top-down approach. \n",
    "\n",
    "Our ultimate goal is derive $p(\\boldsymbol{y}^*|X^*,\\boldsymbol{y}, X)$ at new inputs $X^*$. This can be written as:\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\boldsymbol{y}^*|X^*,\\boldsymbol{y}, X) = \\int p(\\boldsymbol{y}^*|\\boldsymbol{f}^*)p(\\boldsymbol{f}^*|X^*,\\boldsymbol{y}, X)d\\boldsymbol{f}^*\n",
    "\\tag{pred post new}\n",
    "\\end{equation}\n",
    "\n",
    "Here, $p(\\boldsymbol{f}^*|X^*,\\boldsymbol{y}, X)$ is the posterior distribution at inputs $X^*$. Once we derive posterior $p(\\boldsymbol{f}|\\boldsymbol{y},X)$, We can find $p(\\boldsymbol{f}^*|X^*,\\boldsymbol{y}, X)$ like following:\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\boldsymbol{f}^*|X^*, \\boldsymbol{y}, X) = \\int p(\\boldsymbol{f}^*|X^*, \\boldsymbol{f}, X)p(\\boldsymbol{f}|\\boldsymbol{y}, X)d\\boldsymbol{f}\n",
    "\\tag{post new}\n",
    "\\end{equation}\n",
    "\n",
    "Here, $p(\\boldsymbol{f}^*|X^*, \\boldsymbol{f}, X)$ is a [conditional Gaussian distribution](https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Conditional_distributions) with the following closed form:\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\boldsymbol{f}^*|X^*, \\boldsymbol{f}, X) \\sim \\mathcal{N}(\\boldsymbol{m}_{f^*}+K_{f^*f}K_{ff}^{-1}(\\boldsymbol{f}-\\boldsymbol{m}_{f}), K_{f^*f^*} - K_{f^*f}K_{ff}^{-1}K_{ff^*})\n",
    "\\tag{cond}\n",
    "\\end{equation}\n",
    "\n",
    "Posterior $p(\\boldsymbol{f}|\\boldsymbol{y}, X)$ can be derived following \"Bayes' rule for Gaussians\" (section 2.2.6.2 in [pml book2](https://probml.github.io/pml-book/book2.html)):\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\boldsymbol{f}|\\boldsymbol{y}, X) \\sim \\mathcal{N}(\\boldsymbol{m}_f + K_{ff}\\left(K_{ff}+\\sigma_n^2I\\right)^{-1}(\\boldsymbol{y} - \\boldsymbol{m}_f), K_{ff} - K_{ff}\\left(K_{ff} + \\sigma_n^2I\\right)^{-1}K_{ff})\n",
    "\\tag{post}\n",
    "\\end{equation}\n",
    "\n",
    "We can now substitute Eq. (post) and Eq. (cond) in Eq. (post new). The integral can be solved with using Eq. 2.90 in section 2.2.6.2 in [pml book2](https://probml.github.io/pml-book/book2.html) and also mentioned in Eq. (int gaussians) in Appendix.\n",
    "\n",
    "\\begin{align}\n",
    "p(\\boldsymbol{f}^*|X^*, \\boldsymbol{y}, X) &\\sim \\mathcal{N}(\\boldsymbol{\\mu}^*, \\Sigma^*)\\\\\n",
    "\\boldsymbol{\\mu}^* &= \\boldsymbol{m}_{f^*}+K_{f^*f}K_{ff}^{-1}(\\left[\\boldsymbol{m}_f + K_{ff}\\left(K_{ff}+\\sigma_n^2I\\right)^{-1}(\\boldsymbol{y} - \\boldsymbol{m}_f)\\right]-\\boldsymbol{m}_{f})\\\\\n",
    "&=\\boldsymbol{m}_{f^*}+K_{f^*f}K_{ff}^{-1}(K_{ff}\\left(K_{ff}+\\sigma_n^2I\\right)^{-1}(\\boldsymbol{y} - \\boldsymbol{m}_f))\\\\\n",
    "&=\\boldsymbol{m}_{f^*}+K_{f^*f}\\left(K_{ff}+\\sigma_n^2I\\right)^{-1}(\\boldsymbol{y} - \\boldsymbol{m}_f)\\\\\n",
    "\\\\\n",
    "\\Sigma^* &= K_{f^*f^*} - K_{f^*f}K_{ff}^{-1}K_{ff^*} + K_{f^*f}K_{ff}^{-1}\\left[K_{ff} - K_{ff}\\left(K_{ff} + \\sigma_n^2I\\right)^{-1}K_{ff}\\right]K_{ff}^{-1}K_{ff^*}\\\\\n",
    "&=K_{f^*f^*} - K_{f^*f}K_{ff}^{-1}K_{ff^*} + K_{f^*f}\\left[I - \\left(K_{ff} + \\sigma_n^2I\\right)^{-1}K_{ff}\\right]K_{ff}^{-1}K_{ff^*}\\\\\n",
    "&=K_{f^*f^*} - K_{f^*f}K_{ff}^{-1}K_{ff^*} + K_{f^*f}\\left[K_{ff}^{-1} - \\left(K_{ff} + \\sigma_n^2I\\right)^{-1}\\right]K_{ff^*}\\\\\n",
    "&=K_{f^*f^*} - K_{f^*f}K_{ff}^{-1}K_{ff^*} + K_{f^*f}K_{ff}^{-1}K_{ff^*} - K_{f^*f}\\left(K_{ff} + \\sigma_n^2I\\right)^{-1}K_{ff^*}\\\\\n",
    "&=K_{f^*f^*} - K_{f^*f}\\left(K_{ff} + \\sigma_n^2I\\right)^{-1}K_{ff^*}\\\\\n",
    "p(\\boldsymbol{f}^*|X^*, \\boldsymbol{y}, X) &\\sim \\mathcal{N}(\\boldsymbol{m}_{f^*}+K_{f^*f}\\left(K_{ff}+\\sigma_n^2I\\right)^{-1}(\\boldsymbol{y} - \\boldsymbol{m}_f), K_{f^*f^*} - K_{f^*f}\\left(K_{ff} + \\sigma_n^2I\\right)^{-1}K_{ff^*})\n",
    "\\end{align}\n",
    "\n",
    "Now, we are almost there. Plugging in the above formula in Eq. (pred post) and using known result in Eq. (int gaussians), we get the predictive posterior as following:\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\boldsymbol{y}^*|X^*,\\boldsymbol{y}, X) \\sim \\mathcal{N}(\\boldsymbol{m}_{f^*}+K_{f^*f}\\left(K_{ff}+\\sigma_n^2I\\right)^{-1}(\\boldsymbol{y} - \\boldsymbol{m}_f), K_{f^*f^*} - K_{f^*f}\\left(K_{ff} + \\sigma_n^2I\\right)^{-1}K_{ff^*} + \\sigma_n^2I)\n",
    "\\end{equation}\n",
    "\n",
    "> Note: We did not exploit the special structure of likelihood variance $\\sigma_n^2I$ anywhere, so, these derivations hold true for full rank likelihood covariance matrices also.\n",
    "\n",
    "### Optimization\n",
    "\n",
    "We perform type-II likelihood estimation (in other words, minimize log marginal likelihood or evidence term). Our goal is to find optimal model $\\mathcal{M}$ represented by prior (or kernel) hyperparameters and likelihood hyperparameters. We can get the log marginal likelihood using Eq. (int gaussians):\n",
    "\n",
    "\\begin{align}\n",
    "p(\\boldsymbol{y}|X, \\mathcal{M}) &= \\int p(\\boldsymbol{y}|\\boldsymbol{f}) p(\\boldsymbol{f})d\\boldsymbol{f}\\\\\n",
    "&\\sim \\int \\mathcal{N}(\\boldsymbol{y}|\\boldsymbol{f}, \\sigma_n^2I) \\mathcal{N}(\\boldsymbol{f}|\\boldsymbol{m}_f, K_{ff})\\\\\n",
    "&\\sim \\mathcal{N}(\\boldsymbol{y}|\\boldsymbol{m}_f, K_{ff}+\\sigma_n^2I)\n",
    "\\end{align}\n",
    "\n",
    "For case of RBF kernel, $\\mathcal{M}$ parameters will be $\\{\\sigma, \\ell, \\sigma_n\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d22415",
   "metadata": {},
   "source": [
    "## Classification (with Laplace approximation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d9576d",
   "metadata": {},
   "source": [
    "We will derive a GP predictive posterior for binary case only because for multi-class, it gets a bit complex. Our assumption for prior over the $\\boldsymbol{f}$ can still be the same but likelihood needs to be changed because $\\boldsymbol{y}$ is no more a real number but rather a binary value e.g. 0 or 1. From Bayesian point-of-view, Bernoulli likelihood would be the most appropriate as a likelihood here:\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\boldsymbol{y}|\\boldsymbol{f}) = \\prod_{i=1}^{N} \\sigma(f_i)^{y_i=1}(1-\\sigma(f_i))^{y_i=0}\n",
    "\\tag{class likelihood}\n",
    "\\end{equation}\n",
    "\n",
    "Since, MVN prior and Bernoulli likelihood are not conjugate, we need to use an approximate method of inference here. We use Laplace approximation to get the MAP estimate $\\boldsymbol{\\hat{f}}$ and by computing the Hessian $H$ of negative log joint (log prior + log likelihood) with respect to $\\boldsymbol{\\hat{f}}$, we can get the posterior distribution as the following:\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\boldsymbol{f}|\\boldsymbol{y}, X) \\sim \\mathcal{N}(\\boldsymbol{\\hat{f}}, H^{-1})\n",
    "\\tag{class post}\n",
    "\\end{equation}\n",
    "\n",
    "Eq. (cond) will be the same in this case, and thus, we can solve Eq. (post new) as we did for regression case, like the following:\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\boldsymbol{f}^*|X^*, \\boldsymbol{y}, X) \\sim \\mathcal{N}(\\boldsymbol{m}_{f^*}+K_{f^*f}K_{ff}^{-1}(\\boldsymbol{\\hat{f}}-\\boldsymbol{m}_{f}), K_{f^*f^*} - K_{f^*f}K_{ff}^{-1}K_{ff^*} + K_{f^*f}K_{ff}^{-1}H^{-1}K_{ff}^{-1}K_{ff^*})\n",
    "\\end{equation}\n",
    "\n",
    "### Optimization\n",
    "\n",
    "To perform Type-II likelihood estimation for binary classification, we first need to derive the log marginal likelihood which can be approximated with Laplace approximation. First, we define the following quantity:\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{\\psi}(\\boldsymbol{f}) \\triangleq \\log p(\\boldsymbol{y}|\\boldsymbol{f}) + \\log p(\\boldsymbol{f})\n",
    "\\end{equation}\n",
    "\n",
    "Now, computing the log marginal likelihood as suggested in section 3.4.4 of [GPML book](https://gaussianprocess.org/gpml/chapters/RW.pdf):\n",
    "\n",
    "\\begin{align}\n",
    "\\log p(\\boldsymbol{y}|X, \\mathcal{M}) &\\sim \\int p(\\boldsymbol{y}|\\boldsymbol{f}) p(\\boldsymbol{f})d\\boldsymbol{f}\\\\\n",
    "&= \\log \\int \\exp\\left(\\boldsymbol{\\psi}(\\boldsymbol{f})\\right)d\\boldsymbol{f}\\\\\n",
    "&\\thickapprox \\log \\int \\exp\\left(\\boldsymbol{\\psi}(\\boldsymbol{\\hat{f}}) -\\frac{1}{2}(\\mathbf{f}-\\hat{\\mathbf{f}})^{\\top} H(\\mathbf{f}-\\hat{\\mathbf{f}})\\right)d\\boldsymbol{f}\\\\\n",
    "&= \\log \\exp \\boldsymbol{\\psi}(\\boldsymbol{\\hat{f}}) \\int exp\\left(-\\frac{1}{2}(\\mathbf{f}-\\hat{\\mathbf{f}})^{\\top} H(\\mathbf{f}-\\hat{\\mathbf{f}})\\right)d\\boldsymbol{f}\\\\\n",
    "&= \\log p(\\boldsymbol{y}|\\boldsymbol{\\hat{f}}) + \\log p(\\boldsymbol{\\hat{f}}) - \\frac{N}{2}\\log(2\\pi) - \\frac{1}{2}\\log|H^{-1}|\\\\\n",
    "&= \\log p(\\boldsymbol{y}|\\boldsymbol{\\hat{f}}) -\\frac{1}{2}\\boldsymbol{\\hat{f}}^TK_{ff}^{-1}\\boldsymbol{\\hat{f}} - \\frac{1}{2}\\log|K_{ff}| - \\frac{N}{2}\\log(2\\pi) - \\frac{1}{2}\\log|H^{-1}| - \\frac{N}{2}\\log(2\\pi)\n",
    "\\end{align}\n",
    "\n",
    "Our final optimization algorithm would be as following:\n",
    "1. For N iterations do 2. to 4.\n",
    "2. Optimize for $\\boldsymbol{\\hat{f}}$ with M iterations using standard MAP estimation (maybe use non-centered parametrization).\n",
    "3. Compute gradient of parameters of $\\mathcal{M}$ w.r.t. log marginal likelihood\n",
    "4. Update parameters of $\\mathcal{M}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644880e8",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "\\begin{equation}\n",
    "\\int \\mathcal{N}(\\boldsymbol{y}|W\\boldsymbol{x}+\\boldsymbol{b}, \\Sigma) \\mathcal{N}(\\boldsymbol{x}|\\boldsymbol{\\mu}, K) = \\mathcal{N}(\\boldsymbol{y}|W\\boldsymbol{\\mu}+b, WKW^T+\\Sigma)\n",
    "\\tag{int gaussians}\n",
    "\\end{equation}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ajax]",
   "language": "python",
   "name": "conda-env-ajax-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
